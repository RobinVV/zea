{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install zea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Using backend 'jax'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758438658.962206  905083 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758438658.966328  905083 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1758438658.978618  905083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758438658.978634  905083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758438658.978636  905083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1758438658.978637  905083 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "WARNING:2025-09-21 07:11:10,198:jax._src.xla_bridge:966: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import ops\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from zea import init_device\n",
    "from zea.visualize import set_mpl_style\n",
    "from zea.display import scan_convert_2d, inverse_scan_convert_2d\n",
    "from zea.utils import translate\n",
    "\n",
    "init_device(verbose=False)\n",
    "set_mpl_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: ❗️ It is recommended to use \u001b[34mnumpy\u001b[0m backend for `fit_scan_cone()`.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this is a synthetic PLAX view image generated by a diffusion model.\n",
    "url = \"https://raw.githubusercontent.com/tue-bmd/zea/main/docs/source/notebooks/assets/plax.png\"\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).convert(\"RGBA\")\n",
    "\n",
    "# Split channels\n",
    "r, g, b, a = img.split()\n",
    "\n",
    "# Composite onto a black background (RGB = 0,0,0)\n",
    "black_bg = Image.new(\"RGBA\", img.size, (0, 0, 0, 255))\n",
    "img = Image.alpha_composite(black_bg, img)\n",
    "\n",
    "# Convert to grayscale\n",
    "img = img.convert(\"L\")\n",
    "\n",
    "# Convert to numpy\n",
    "img_np = np.asarray(img).astype(np.float32)\n",
    "# Convert to polar domain\n",
    "img_polar_np = inverse_scan_convert_2d(img_np)\n",
    "\n",
    "# plotting\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot input image\n",
    "ax1.imshow(img_np, cmap=\"gray\")\n",
    "ax1.set_title(\"Cartesian\", fontsize=15)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# Plot output with measurements\n",
    "ax2.imshow(img_polar_np, cmap=\"gray\")\n",
    "ax2.set_title(\"Polar\", fontsize=15)\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cartesian_polar.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cartesian Polar input](./cartesian_polar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the downstream task function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zea.models.echonetlvh import EchoNetLVH\n",
    "\n",
    "# Load model from zeahub\n",
    "model = EchoNetLVH.from_preset(\"echonetlvh\")\n",
    "\n",
    "def lvid_downstream_task(posterior_sample):\n",
    "    posterior_sample_sc = scan_convert_2d(\n",
    "        posterior_sample,\n",
    "        rho_range=(0, ops.shape(img_polar_np)[0]),\n",
    "        theta_range=np.deg2rad((-45, 45))\n",
    "    )\n",
    "    logits = model(posterior_sample_sc)\n",
    "    key_points = model.extract_key_points_as_indices(logits)[0]\n",
    "    lvid_bottom_coords, lvid_top_coords = key_points[1], key_points[2]\n",
    "    lvid_length = ops.sqrt(\n",
    "        ops.sum((lvid_top_coords - lvid_bottom_coords) ** 2)\n",
    "    )\n",
    "    return lvid_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a sparse acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zea.agent.selection import EquispacedLines\n",
    "\n",
    "batch = ops.image.resize(ops.convert_to_tensor(img_polar_np[None, ..., None]), (256, 256))\n",
    "batch_normalized = translate(batch, range_from=(0, 255), range_to=(-1, 1))\n",
    "\n",
    "img_shape = (256, 256)\n",
    "line_thickness = 1\n",
    "factor = 32\n",
    "agent = EquispacedLines(\n",
    "    n_actions=img_shape[1] // line_thickness // factor,\n",
    "    n_possible_actions=img_shape[1] // line_thickness,\n",
    "    img_width=img_shape[1],\n",
    "    img_height=img_shape[0],\n",
    ")\n",
    "\n",
    "_, mask = agent.sample()\n",
    "mask = ops.expand_dims(mask, axis=-1)\n",
    "\n",
    "measurements = ops.where(mask, batch, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('measurements.png', measurements[0,...,0], cmap=\"gray\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Measurements](./measurements.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the sparse measurements into a 3-frame measurement buffer, since we use a 3-frame diffusion model for perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_buffer = ops.concatenate((ops.zeros((1, *img_shape, 2)), measurements), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7edd39463a44178ae1a9feefdaaec76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/858 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a664d818b1b4f189ff89dd231198b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.weights.h5:   0%|          | 0.00/31.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from zea.models.diffusion import DiffusionModel\n",
    "diffusion_model = DiffusionModel.from_preset(\"diffusion-echonetlvh-3-frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m posterior_samples = \u001b[43mdiffusion_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mposterior_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeasurement_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43momega\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zea/zea/models/diffusion.py:257\u001b[39m, in \u001b[36mDiffusionModel.posterior_sample\u001b[39m\u001b[34m(self, measurements, n_samples, n_steps, initial_step, initial_samples, seed, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m seed1, seed2 = split_seed(seed, \u001b[32m2\u001b[39m)\n\u001b[32m    252\u001b[39m initial_noise = keras.random.normal(\n\u001b[32m    253\u001b[39m     shape=ops.shape(measurements),\n\u001b[32m    254\u001b[39m     seed=seed1,\n\u001b[32m    255\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreverse_conditional_diffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_noise\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiffusion_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# returns: (batch_size, n_samples, *input_shape)\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.reshape(out, (shape[\u001b[32m0\u001b[39m], n_samples, *shape[\u001b[32m1\u001b[39m:]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zea/zea/models/diffusion.py:646\u001b[39m, in \u001b[36mDiffusionModel.reverse_conditional_diffusion\u001b[39m\u001b[34m(self, measurements, initial_noise, diffusion_steps, initial_samples, initial_step, stochastic_sampling, seed, verbose, track_progress_type, disable_jit, **kwargs)\u001b[39m\n\u001b[32m    642\u001b[39m     loop_state = (next_noisy_images, pred_images, seed)\n\u001b[32m    644\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_state\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m _, pred_images, _ = \u001b[43mfori_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiffusion_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnext_noisy_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_noise\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# can't jit this with progbar or tracking intermediate values\u001b[39;49;00m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_jit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrack_progress_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_jit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pred_images\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zea/zea/tensor_ops.py:1261\u001b[39m, in \u001b[36mfori_loop\u001b[39m\u001b[34m(lower, upper, body_fun, init_val, disable_jit)\u001b[39m\n\u001b[32m   1259\u001b[39m val = init_val\n\u001b[32m   1260\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lower, upper):\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m     val = \u001b[43mbody_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/zea/zea/models/diffusion.py:606\u001b[39m, in \u001b[36mDiffusionModel.reverse_conditional_diffusion.<locals>.step_fn\u001b[39m\u001b[34m(step, loop_state)\u001b[39m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep_fn\u001b[39m(step, loop_state):\n\u001b[32m    604\u001b[39m     noisy_images, pred_images, seed = loop_state\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     diffusion_times = \u001b[43mbase_diffusion_times\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\n\u001b[32m    607\u001b[39m     noise_rates, signal_rates = \u001b[38;5;28mself\u001b[39m.diffusion_schedule(diffusion_times)\n\u001b[32m    609\u001b[39m     \u001b[38;5;66;03m# remix the predicted components using the next signal and noise rates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:579\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    577\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/jax/_src/numpy/ufunc_api.py:180\u001b[39m, in \u001b[36mufunc.__call__\u001b[39m\u001b[34m(self, out, where, *args)\u001b[39m\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m call = \u001b[38;5;28mself\u001b[39m.__static_props[\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_vectorized\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "posterior_samples = diffusion_model.posterior_sample(\n",
    "    measurements=measurement_buffer,\n",
    "    mask=mask, \n",
    "    n_samples=1,\n",
    "    n_steps=500,\n",
    "    omega=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
