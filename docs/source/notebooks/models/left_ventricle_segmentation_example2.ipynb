{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left ventricle segmentation\n",
    "\n",
    "Here we use a nnU-Net segmentation model trained on the [augmented CAMUS](https://arxiv.org/abs/2502.20100) dataset within the zea framework to segment the left ventricle and myocardium in apical two and four chamber views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tue-bmd/zea/blob/main/docs/source/notebooks/models/left_ventricle_segmentation_example2.ipynb)\n",
    "&nbsp;\n",
    "[![View on GitHub](https://img.shields.io/badge/GitHub-View%20Source-blue?logo=github)](https://github.com/tue-bmd/zea/blob/main/docs/source/notebooks/models/left_ventricle_segmentation_example2.ipynb)\n",
    "&nbsp;\n",
    "[![Hugging Face model](https://img.shields.io/badge/Hugging%20Face-Model-yellow?logo=huggingface)](https://huggingface.co/gillesvdv/augmented_camus_seg)\n",
    "&nbsp;\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-Paper-b31b1b.svg)](https://arxiv.org/abs/2502.20100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install zea\n",
    "%pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Using backend 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import ops\n",
    "\n",
    "from zea import init_device\n",
    "from zea.backend.tensorflow.dataloader import make_dataloader\n",
    "from zea.visualize import plot_image_grid, set_mpl_style\n",
    "\n",
    "init_device(verbose=False)\n",
    "set_mpl_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load segmentation onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zea.models.lv_segmentation import AugmentedCamusSeg\n",
    "\n",
    "INFERENCE_SIZE = 256\n",
    "model = AugmentedCamusSeg()\n",
    "# load weights from huggingface\n",
    "model.custom_load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load some data (for more info see the [zea_data_example](../data/zea_data_example.ipynb) notebook), and perform inference on the data to segment the left ventricle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Arqee contains a helper function for visualization of segmentation masks\n",
    "!pip install git+https://github.com/GillesVanDeVyver/arqee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Using pregenerated dataset info file: \u001b[33m/root/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val/dataset_info.yaml\u001b[0m ...\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: ...for reading file paths in \u001b[33m/root/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Dataset was validated on \u001b[32mSeptember 29, 2025\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Remove \u001b[33m/root/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val/validated.flag\u001b[0m if you want to redo validation.\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: \u001b[38;5;214mWARNING\u001b[0m H5Generator: Not all files have the same shape. This can lead to issues when resizing images later....\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: H5Generator: Shuffled data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: H5Generator: Shuffled data.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import arqee\n",
    "\n",
    "n_imgs = 16\n",
    "val_dataset = make_dataloader(\n",
    "    \"hf://zeahub/camus-sample/val\",\n",
    "    key=\"data/image_sc\",\n",
    "    batch_size=n_imgs,\n",
    "    shuffle=True,\n",
    "    image_range=[-45, 0],\n",
    "    clip_image_range=True,\n",
    "    normalization_range=[-1, 1],\n",
    "    image_size=(INFERENCE_SIZE, INFERENCE_SIZE),\n",
    "    resize_type=\"resize\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "batch = next(iter(val_dataset))\n",
    "batch_np = ops.convert_to_numpy(batch)\n",
    "\n",
    "# ONNX expects NCHW: (batch, channels, depth, width)\n",
    "onnx_input = np.transpose(batch_np, (0, 3, 1, 2))\n",
    "\n",
    "outputs = model.call(onnx_input)\n",
    "\n",
    "outputs = np.array(outputs)\n",
    "# predicted class = class with the highest score for each pixel\n",
    "masks = np.argmax(outputs, axis=1)\n",
    "\n",
    "fig, _ = plot_image_grid(masks, vmin=0, vmax=1)\n",
    "axes = fig.axes[:n_imgs]\n",
    "for ax, mask, us_image in zip(axes, masks, batch_np):\n",
    "    visual = arqee.create_visualization(us_image[:, :, -1], mask, labels=[1, 2])\n",
    "    ax.imshow(visual)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"augmented_camus_seg_output.png\", dpi=100)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nnU-Net](./augmented_camus_seg_output.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
