{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left ventricle segmentation\n",
    "\n",
    "Here we use the [EchoNetDynamic](https://echonet.github.io/dynamic/) model within the zea framework to segment left ventricle in echocardiograms. Note that in this notebook, we use the original model, but perform inference on the [CAMUS](https://www.creatis.insa-lyon.fr/Challenge/camus/) dataset, which is a different dataset than the one used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tue-bmd/zea/blob/main/docs/source/notebooks/models/left_ventricle_segmentation_example.ipynb)\n",
    "&nbsp;\n",
    "[![View on GitHub](https://img.shields.io/badge/GitHub-View%20Source-blue?logo=github)](https://github.com/tue-bmd/zea/blob/main/docs/source/notebooks/models/left_ventricle_segmentation_example.ipynb)\n",
    "&nbsp;\n",
    "[![Hugging Face model](https://img.shields.io/badge/Hugging%20Face-Model-yellow?logo=huggingface)](https://huggingface.co/zeahub/echonet-dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install zea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Using backend 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# NOTE: should be `tensorflow` or `jax` for EchoNetDynamic\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import ops\n",
    "\n",
    "from zea import init_device, log\n",
    "from zea.backend.tensorflow.dataloader import make_dataloader\n",
    "from zea.tools.selection_tool import add_shape_from_mask\n",
    "from zea.utils import translate\n",
    "from zea.visualize import plot_image_grid, set_mpl_style\n",
    "\n",
    "init_device(verbose=False)\n",
    "set_mpl_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load EchoNetDynamic from `zeahub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Available built-in zea presets for EchoNetDynamic: ['echonet-dynamic']\n"
     ]
    }
   ],
   "source": [
    "from zea.models.echonet import EchoNetDynamic, INFERENCE_SIZE\n",
    "\n",
    "presets = list(EchoNetDynamic.presets.keys())\n",
    "log.info(f\"Available built-in zea presets for EchoNetDynamic: {presets}\")\n",
    "\n",
    "model = EchoNetDynamic.from_preset(\"echonet-dynamic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load some data (for more info see the [zea_data_example](../data/zea_data_example.ipynb) notebook), and perform inference on the data to segment the left ventricle. Note that the performance of the model is not as good on the CAMUS dataset as it is on the original EchoNetDynamic dataset, but it still provides a good example of how to use the model within the zea framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Using pregenerated dataset info file: \u001b[33m/root/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val/dataset_info.yaml\u001b[0m ...\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: ...for reading file paths in \u001b[33m/root/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Dataset was validated on \u001b[32mSeptember 12, 2025\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Remove \u001b[33m/root/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val/validated.flag\u001b[0m if you want to redo validation.\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: \u001b[38;5;214mWARNING\u001b[0m H5Generator: Not all files have the same shape. This can lead to issues when resizing images later....\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: H5Generator: Shuffled data.\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: H5Generator: Shuffled data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_601155/1368422497.py:29: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "n_imgs = 16\n",
    "val_dataset = make_dataloader(\n",
    "    \"hf://zeahub/camus-sample/val\",\n",
    "    key=\"data/image_sc\",\n",
    "    batch_size=n_imgs,\n",
    "    shuffle=True,\n",
    "    image_range=[-45, 0],\n",
    "    clip_image_range=True,\n",
    "    normalization_range=[-1, 1],\n",
    "    image_size=(INFERENCE_SIZE, INFERENCE_SIZE),\n",
    "    resize_type=\"resize\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "batch = next(iter(val_dataset))\n",
    "# grayscale to RGB for the EchoNetDynamic model\n",
    "rgb_batch = ops.concatenate([batch, batch, batch], axis=-1)\n",
    "\n",
    "masks = model(rgb_batch)\n",
    "masks = ops.squeeze(masks, axis=-1)\n",
    "masks = ops.convert_to_numpy(masks)\n",
    "\n",
    "batch = translate(rgb_batch, [-1, 1], [0, 1])\n",
    "fig, _ = plot_image_grid(batch, vmin=0, vmax=1)\n",
    "axes = fig.axes[:n_imgs]\n",
    "for ax, mask in zip(axes, masks):\n",
    "    add_shape_from_mask(ax, mask, color=\"red\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"echonet_output.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EchoNet-Dynamic Example Output](./echonet_output.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
